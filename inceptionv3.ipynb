{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.autograd import Variable\nimport time\nimport copy\nimport cv2 \nimport numpy as np\ninput_path = \"../input/data-chamber/DATA_CHAMBER_2021/\" \nuse_gpu = torch.cuda.is_available()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:06:59.827208Z","iopub.execute_input":"2021-11-28T12:06:59.827897Z","iopub.status.idle":"2021-11-28T12:07:00.921629Z","shell.execute_reply.started":"2021-11-28T12:06:59.827843Z","shell.execute_reply":"2021-11-28T12:07:00.920820Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n    \n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:00.923799Z","iopub.execute_input":"2021-11-28T12:07:00.924326Z","iopub.status.idle":"2021-11-28T12:07:00.929771Z","shell.execute_reply.started":"2021-11-28T12:07:00.924276Z","shell.execute_reply":"2021-11-28T12:07:00.929122Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:00.931368Z","iopub.execute_input":"2021-11-28T12:07:00.931840Z","iopub.status.idle":"2021-11-28T12:07:00.938268Z","shell.execute_reply.started":"2021-11-28T12:07:00.931627Z","shell.execute_reply":"2021-11-28T12:07:00.937342Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract = False, use_pretrained=True):\n    \n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet18\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n        \n    elif model_name == \"resnet50\":\n        \"\"\" Resnet50\n        \"\"\"\n        model_ft = models.resnet50(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG19_bn\n        \"\"\"\n        model_ft = models.vgg19_bn().load_state_dict(torch.load(\"../input/vgg19bn/vgg19_bn.pth\"))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_features = vgg16.classifier[6].in_features\n        features = list(vgg16.classifier.children())[:-1] # Remove last layer\n        features.extend([nn.Linear(num_features, len(num_classes))]) # Add our layer with 4 outputs\n        vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=False)\n        model_ft.load_state_dict(torch.load('../input/pretrained-pytorch-models/inception_v3_google-1a9a5a14.pth'))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\nmodel_ft, input_size = initialize_model('inception', 3,feature_extract = False, use_pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:00.939669Z","iopub.execute_input":"2021-11-28T12:07:00.940178Z","iopub.status.idle":"2021-11-28T12:07:06.649529Z","shell.execute_reply.started":"2021-11-28T12:07:00.939894Z","shell.execute_reply":"2021-11-28T12:07:06.648713Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def opening(img):\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=1)\n    img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n    return img_dilation\ndef denoise(img):\n    \n    denoise_img = cv2.bilateralFilter(img, 15, 75, 75)\n    return denoise_img","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:06.650714Z","iopub.execute_input":"2021-11-28T12:07:06.651003Z","iopub.status.idle":"2021-11-28T12:07:06.657768Z","shell.execute_reply.started":"2021-11-28T12:07:06.650950Z","shell.execute_reply":"2021-11-28T12:07:06.656986Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow)/255\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131*(contrast + 127)/(127*(131-contrast))\n        alpha_c = f\n        gamma_c = 127*(1-f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:06.659077Z","iopub.execute_input":"2021-11-28T12:07:06.659601Z","iopub.status.idle":"2021-11-28T12:07:06.669191Z","shell.execute_reply.started":"2021-11-28T12:07:06.659551Z","shell.execute_reply":"2021-11-28T12:07:06.668410Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import cm\ndef preprocessing(img):\n    return Image.fromarray(np.uint8(apply_brightness_contrast(opening(denoise(np.array(img))),0,16)))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:06.670503Z","iopub.execute_input":"2021-11-28T12:07:06.671108Z","iopub.status.idle":"2021-11-28T12:07:06.680241Z","shell.execute_reply.started":"2021-11-28T12:07:06.670866Z","shell.execute_reply":"2021-11-28T12:07:06.679543Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\ndata_transforms = {\n    'train': transforms.Compose([\n        preprocessing,\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n    \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n    ]),\n    'test': transforms.Compose([\n        preprocessing,\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n\nimage_datasets = {\n    'train':\n    ImageFolderWithPaths(input_path + 'train', data_transforms['train']),\n    'test': \n    ImageFolderWithPaths(input_path + 'test', data_transforms['test'])\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train','test']}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=2),  # for Kaggle\n    'test':\n    torch.utils.data.DataLoader(image_datasets['test'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=2)  # for Kaggle\n}\nclass_names = image_datasets['train'].classes\n\n# See some statistics\nprint(dataloaders)\nlen(dataloaders['train'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:06.681598Z","iopub.execute_input":"2021-11-28T12:07:06.682017Z","iopub.status.idle":"2021-11-28T12:07:11.665885Z","shell.execute_reply.started":"2021-11-28T12:07:06.681931Z","shell.execute_reply":"2021-11-28T12:07:11.665203Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nplt.ion()   # interactive mode\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes,_ = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:11.667635Z","iopub.execute_input":"2021-11-28T12:07:11.668263Z","iopub.status.idle":"2021-11-28T12:07:18.408088Z","shell.execute_reply.started":"2021-11-28T12:07:11.668197Z","shell.execute_reply":"2021-11-28T12:07:18.407110Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=2, is_inception=False):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    loss_values = []\n    acc_values = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train','test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels,_ in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    \n                    if is_inception and phase == 'train':\n                        \n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                    \n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                del inputs,labels\n            if phase == 'train':\n                scheduler.step()\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            loss_values.append(epoch_loss)\n            acc_values.append(epoch_acc)\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model,acc_values,loss_values","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:18.412153Z","iopub.execute_input":"2021-11-28T12:07:18.412487Z","iopub.status.idle":"2021-11-28T12:07:18.433857Z","shell.execute_reply.started":"2021-11-28T12:07:18.412426Z","shell.execute_reply":"2021-11-28T12:07:18.433115Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels,_) in enumerate(dataloaders['test']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:18.439118Z","iopub.execute_input":"2021-11-28T12:07:18.441113Z","iopub.status.idle":"2021-11-28T12:07:18.451191Z","shell.execute_reply.started":"2021-11-28T12:07:18.441062Z","shell.execute_reply":"2021-11-28T12:07:18.450439Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\ndef test_model(model, criterion, optimizer):\n    labels_input=list()\n    labels_output=list()\n    vid_id = list()\n    for phase in ['test']:\n        model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels, fname in dataloaders[phase]:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels_input= labels_input + labels.tolist()\n            for f in fname:\n                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n            outputs = model(inputs)\n            \n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            labels_output= labels_output + preds.tolist()\n    return labels_input,labels_output,vid_id\n            ","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:18.455901Z","iopub.execute_input":"2021-11-28T12:07:18.457872Z","iopub.status.idle":"2021-11-28T12:07:18.467005Z","shell.execute_reply.started":"2021-11-28T12:07:18.457823Z","shell.execute_reply":"2021-11-28T12:07:18.466270Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def plot_history(history,loss,acc): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(loss, 'r', label=\"loss\")\n    ax1.grid(True)\n    ax1.set_xlabel('epoch')\n    ax1.set_ylabel('loss', color='r')\n    ax1.legend(loc=\"best\", fontsize=9)    \n    ax1.tick_params('y', colors='r')\n\n    ax2 = ax1.twinx()\n    ax2.plot(acc, 'g', label=\"acc\")\n    ax2.legend(loc=\"lower right\", fontsize=9)\n    ax2.set_ylabel('accuracy', color='g')        \n    ax2.tick_params('y', colors='g')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:18.470752Z","iopub.execute_input":"2021-11-28T12:07:18.472885Z","iopub.status.idle":"2021-11-28T12:07:18.481594Z","shell.execute_reply.started":"2021-11-28T12:07:18.470994Z","shell.execute_reply":"2021-11-28T12:07:18.480865Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft = model_ft.to(device)\n\nparams_to_update = []\nfor name,param in model_ft.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\noptimizer_conv = optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n\ncriterion = nn.CrossEntropyLoss()\n# Decay LR by a factor of 0.1 every epoch\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=1, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:18.483039Z","iopub.execute_input":"2021-11-28T12:07:18.483763Z","iopub.status.idle":"2021-11-28T12:07:21.985300Z","shell.execute_reply.started":"2021-11-28T12:07:18.483711Z","shell.execute_reply":"2021-11-28T12:07:21.984467Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model_ft,acc,loss = train_model(model_ft, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=10, is_inception=True) ","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:07:21.986889Z","iopub.execute_input":"2021-11-28T12:07:21.987174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(model_ft,loss,acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model_ft)\n\n# plt.ioff()\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true,y_pred,vid_id = test_model(model_ft, criterion, optimizer_conv)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_true,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport glob\n\n\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),columns =['y_true','y_pred','vid_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)\n\nvid_list = list(set(df['vid_id'].values))\ny_true = []\ny_pred = []\nfor vid in vid_list:\n    tmp_df = df[df['vid_id']==vid]\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}